<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Browser Indoor Navigation (Color QR + Full Navigation + Obstacle Alerts)</title>
  <style>
    body { font-family: system-ui, -apple-system, "Segoe UI", Roboto, Arial; padding: 12px; background:#f7fafc; color:#111; }
    header { display:flex; align-items:center; gap:12px; }
    h1 { margin:0; font-size:18px; }
    .controls { margin:8px 0; display:flex; gap:8px; flex-wrap:wrap; }
    button, select { padding:8px 10px; font-size:14px; }
    #preview { width: 820px; max-width:100%; height: 360px; background:#222; display:block; margin-top:8px; object-fit:cover; }
    #canvasDisp { display:none; } /* internal canvas used for processing */
    #log { width:820px; max-width:100%; height:120px; overflow:auto; background:#fff; border:1px solid #ddd; padding:8px; margin-top:8px; white-space:pre-wrap;}
    #overlayText { margin-top:6px; font-weight:600; color:#444; }
    #result { margin-top:6px; color:#222; }
    .map-modal { position:fixed; inset:0; display:none; align-items:center; justify-content:center; background:rgba(0,0,0,0.4); }
    .map-modal .box { background:#fff; padding:12px; max-width:900px; width:95%; max-height:85%; overflow:auto; border-radius:6px; }
    .small { font-size:13px; color:#666; }
    #debugMasks { display:flex; gap:8px; margin-top:8px; align-items:center; }
    #debugMasks canvas { border:1px solid #ccc; width:120px; height:120px; }
    .mask-label { text-align:center; font-size:12px; color:#333; }
    .scan-progress { margin-top: 10px; padding: 8px; background: #e6f3ff; border-radius: 4px; }
    .found-qr { color: green; font-weight: bold; }
    .pending-qr { color: #666; }
  </style>

  <!-- jsQR and OpenCV -->
  <script src="https://cdn.jsdelivr.net/npm/jsqr@1.4.0/dist/jsQR.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <!-- TensorFlow.js and COCO-SSD model for object detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <header>
    <h1>Browser Indoor Navigation (Color QR + Object Alerts)</h1>
    <div class="small">Multi-color QR â†’ navigation & voice (no backend)</div>
  </header>

  <div class="controls">
    <label>QR Color:
      <select id="colorFilter"><option>Any</option><option>Red</option><option>Green</option><option>Blue</option></select>
    </label>
    <button id="startBtn">Start Scan</button>
    <button id="stopBtn">Stop Scan</button>
    <button id="voiceDestBtn">Voice-Dest & Start</button>
    <button id="mapBtn">Show Map</button>
    <button id="restartBtn">Restart Scanner</button>
    <label style="margin-left:8px;">
      <input type="checkbox" id="enableDetect" checked> Enable Object Detection
    </label>
  </div>

  <div id="overlayText">Initializing...</div>
  <video id="video" autoplay playsinline style="display:none"></video>
  <canvas id="canvasDisp"></canvas>
  <img id="preview" alt="camera preview" />

  <div class="scan-progress" id="scanProgress">
    <div>Scanning Progress:</div>
    <div id="progressRed" class="pending-qr">ðŸ”´ Red QR: Not found</div>
    <div id="progressGreen" class="pending-qr">ðŸŸ¢ Green QR: Not found</div>
    <div id="progressBlue" class="pending-qr">ðŸ”µ Blue QR: Not found</div>
  </div>

  <div id="result"></div>
  <div id="log"></div>

  <div class="map-modal" id="mapModal">
    <div class="box">
      <h3>Map Preview</h3>
      <canvas id="mapCanvas" width="900" height="600" style="background:#fff;border:1px solid #ddd"></canvas>
      <div style="text-align:right; margin-top:8px;">
        <button id="closeMap">Close</button>
      </div>
    </div>
  </div>

<script>
/* ======= UI elements ======= */
const video = document.getElementById('video');
const canvasDisp = document.getElementById('canvasDisp');
const ctxDisp = canvasDisp.getContext('2d', { willReadFrequently: true });
const preview = document.getElementById('preview');
const overlayText = document.getElementById('overlayText');
const resultEl = document.getElementById('result');
const logEl = document.getElementById('log');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const voiceDestBtn = document.getElementById('voiceDestBtn');
const colorFilterEl = document.getElementById('colorFilter');
const mapBtn = document.getElementById('mapBtn');
const mapModal = document.getElementById('mapModal');
const mapCanvas = document.getElementById('mapCanvas');
const closeMap = document.getElementById('closeMap');
const restartBtn = document.getElementById('restartBtn');
const progressRed = document.getElementById('progressRed');
const progressGreen = document.getElementById('progressGreen');
const progressBlue = document.getElementById('progressBlue');
const enableDetectCheckbox = document.getElementById('enableDetect');

const log = (m) => { console.log(m); logEl.innerText += m + '\n'; logEl.scrollTop = logEl.scrollHeight; };

/* ======= Config & state ======= */
const SCAN_SIZE = 250;
let scanBox = { x: 0, y: 0, size: SCAN_SIZE };
let cvReady = false;
let animationFrameId = null;
let stream = null;
let scannerRunning = false;
let foundResults = new Map();
let scanStartTime = Date.now();
const MAX_SCAN_TIME = 30000;
let currentLocation = null;
let currentNavigationTarget = null;
let latestObstacle = null;
let actionsTriggered = false;

/* ======= Object detection (coco-ssd) globals & tuning ======= */
let cocoModel = null;
let cocoReady = false;
const DETECTION_INTERVAL_MS = 900;  // run detection about every 0.9s
const SCORE_THRESHOLD = 0.45;
const CENTER_TOLERANCE = 0.25; // how close bbox center must be to frame center to be considered "ahead"
const DISTANCE_ESTIMATE_SCALE = 1.6; // heuristic scaling for distance estimate
let lastDetectTime = 0;
const alertCooldown = 3000; // ms per class before repeated alert
const lastAlertAt = {}; // map class->timestamp

/* ======= Graph & helpers - same as your original graph ======= */
const node_coords = {
  "Female Toilet (NGT1)": [2009, 1357],
  "Male Toilet (NGT2)": [1955, 1357],
  "N001 (backdoor)": [2100, 1135],
  "N001": [1907, 1121],
  "N002": [1651, 1097],
  "N003": [1387, 1074],
  "N004": [892, 1097],
  "N005": [638, 1115],
  "N006": [383, 1139],
  "N007": [127, 1158],
  "N008": [4, 1330],
  "Female Toilet (NGT5)": [357, 1350],
  "Male Toilet (NGT4)": [403, 1351],
  "N009": [492, 1330],
  "N010": [822, 1335],
  "N011": [1251, 1340],
  "N012": [1597, 1340],
};

const graph_raw = {
  "Female Toilet (NGT1)": {"Male Toilet (NGT2)": 1.89},
  "N001": {"Female Toilet (NGT1)": 9.00, "N001 (backdoor)": 6.77, "N002": 9.00},
  "N002": {"N003": 9.28},
  "N003": {"N004": 17.35},
  "N004": {"N005": 8.91},
  "N005": {"N006": 8.97},
  "N006": {"Male Toilet (NGT4)": 7.45, "Female Toilet (NGT5)": 7.44, "N007": 8.99},
  "N007": {"N008": 7.40},
  "N008": {"Female Toilet (NGT5)": 12.38},
  "Female Toilet (NGT5)": {"Male Toilet (NGT4)": 1.61},
  "Male Toilet (NGT4)": {"N009": 3.20},
  "N009": {"N010": 11.55},
  "N010": {"N011": 15.02},
  "N011": {"N012": 12.11},
  "N012": {"Male Toilet (NGT2)": 12.55}
};

function add_bidirectional_edges(graph_in) {
  const new_graph = {};
  for (const k in graph_in) new_graph[k] = {};
  for (const from in graph_in) {
    for (const to in graph_in[from]) {
      const w = graph_in[from][to];
      new_graph[from][to] = w;
      if (!new_graph[to]) new_graph[to] = {};
      new_graph[to][from] = w;
    }
  }
  return new_graph;
}
const graph = add_bidirectional_edges(graph_raw);

function dijkstra(gr, start, end) {
  const pq = new MinHeap();
  pq.push({cost:0,node:start,path:[]});
  const visited = new Set();
  while (!pq.empty()) {
    const item = pq.pop();
    const {cost, node, path} = item;
    if (visited.has(node)) continue;
    const newPath = path.concat([node]);
    visited.add(node);
    if (node === end) return {path:newPath, cost};
    const neighbors = gr[node] || {};
    for (const nb in neighbors) {
      if (!visited.has(nb)) pq.push({cost: cost + neighbors[nb], node: nb, path: newPath});
    }
  }
  return {path:[], cost: Infinity};
}
class MinHeap {
  constructor(){ this.a = []; }
  push(x){ this.a.push(x); this._siftUp(); }
  pop(){ if(this.a.length===0) return null; const r=this.a[0]; const last=this.a.pop(); if(this.a.length) { this.a[0]=last; this._siftDown(); } return r; }
  empty(){ return this.a.length===0; }
  _siftUp(){ let i=this.a.length-1; while(i>0){ let p=Math.floor((i-1)/2); if(this.a[p].cost<=this.a[i].cost) break; [this.a[p],this.a[i]]=[this.a[i],this.a[p]]; i=p; } }
  _siftDown(){ let i=0; const n=this.a.length; while(true){ let l=i*2+1; let r=i*2+2; let smallest=i; if(l<n && this.a[l].cost < this.a[smallest].cost) smallest=l; if(r<n && this.a[r].cost < this.a[smallest].cost) smallest=r; if(smallest===i) break; [this.a[i],this.a[smallest]]=[this.a[smallest],this.a[i]]; i=smallest; } }
}

/* ======= Direction helpers ======= */
function get_turn_direction(p1,p2,p3) {
  const v1 = [p2[0]-p1[0], p2[1]-p1[1]];
  const v2 = [p3[0]-p2[0], p3[1]-p2[1]];
  const raw = (Math.atan2(v2[1], v2[0]) - Math.atan2(v1[1], v1[0])) * 180/Math.PI;
  const angle = (raw + 360) % 360;
  if (angle < 45 || angle > 315) return "Move straight";
  if (angle >= 45 && angle < 135) return "Turn right";
  if (angle >= 135 && angle < 225) return "Turn back";
  return "Turn left";
}
function get_initial_direction_simple(p1,p2) {
  const dx = p2[0]-p1[0], dy = p2[1]-p1[1];
  const angle = (Math.atan2(dy,dx) * 180/Math.PI + 360) % 360;
  if (angle >= 315 || angle < 45) return "Move straight";
  if (angle >= 45 && angle < 135) return "Turn right";
  if (angle >= 135 && angle < 225) return "Turn back";
  return "Turn left";
}

/* ======= TTS manager (same as yours) ======= */
const TTS = {
  queue: [],
  speaking: false,
  speak(text, interrupt=false) {
    if (!text) return;
    if (interrupt) {
      this.queue = [];
      if (speechSynthesis.speaking) speechSynthesis.cancel();
    }
    this.queue.push(text);
    this._maybeSpeak();
  },
  _maybeSpeak() {
    if (this.speaking) return;
    const next = this.queue.shift();
    if (!next) return;
    this.speaking = true;
    const utt = new SpeechSynthesisUtterance(next);
    utt.onend = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    utt.onerror = () => { this.speaking = false; setTimeout(()=>this._maybeSpeak(), 80); };
    speechSynthesis.speak(utt);
  }
};

/* ======= Speech recognition availability check (same as yours) ======= */
let SR_AVAILABLE = false;
try {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (SpeechRecognition) SR_AVAILABLE = true;
} catch(e){ SR_AVAILABLE=false; }

/* ======= Color detection functions (kept from your original file) ======= */
/* ... For brevity in the explanation, keep the existing color-masking/extraction/detect functions exactly as in your file ... */
/* We'll reuse detect_colored_qr_in_frame_js(), extractColorChannel(), createColorMask(), detectWithOpenCV(), enhanceBlueContrast() etc. */
/* For clarity I will inline the main ones used (extractColorChannel, createColorMask, enhanceBlueContrast, detect_colored_qr_in_frame_js) - copy them from your original file exactly. */

function createColorMask(imageData, color) {
  const data = imageData.data;
  const maskData = new Uint8ClampedArray(data.length);
  let colorPixels = 0;
  let totalPixels = data.length / 4;
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i];
    const g = data[i + 1];
    const b = data[i + 2];
    let isTargetColor = false;
    if (color === 'red') {
      isTargetColor = (r > g + 30 && r > b + 30 && r > 80) || 
                     (r > 150 && r > g * 1.5 && r > b * 1.5) ||
                     (r > 120 && g < 80 && b < 80);
    } else if (color === 'green') {
      isTargetColor = (g > r + 30 && g > b + 30 && g > 80) || 
                     (g > 150 && g > r * 1.5 && g > b * 1.5) ||
                     (g > 120 && r < 80 && b < 80);
    } else if (color === 'blue') {
      isTargetColor = (b > r + 15 && b > g + 15 && b > 50) || 
                     (b > 100 && b > r * 1.1 && b > g * 1.1) ||
                     (b > 70 && r < 120 && g < 120) ||
                     (b > 60 && b > r && b > g && (r + g) < b * 1.5) ||
                     (b > 40 && b > r * 1.2 && b > g * 1.2 && r < 100 && g < 100);
    }
    if (isTargetColor) {
      colorPixels++;
      maskData[i] = 255; maskData[i + 1] = 255; maskData[i + 2] = 255; maskData[i + 3] = 255;
    } else {
      maskData[i] = 0; maskData[i + 1] = 0; maskData[i + 2] = 0; maskData[i + 3] = 255;
    }
  }
  const colorRatio = colorPixels / totalPixels;
  if (colorRatio > 0.01) {
    console.log(`${color} mask: ${colorPixels}/${totalPixels} pixels (${(colorRatio*100).toFixed(1)}%)`);
  }
  return new ImageData(maskData, imageData.width, imageData.height);
}

function extractColorChannel(imageData, channel) {
  const data = new Uint8ClampedArray(imageData.data);
  let colorPixels = 0;
  let totalPixels = data.length / 4;
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i], g = data[i + 1], b = data[i + 2];
    let intensity;
    let isColorDominant = false;
    if (channel === 'red') {
      intensity = r;
      isColorDominant = (r > g && r > b && r > 50);
      if (isColorDominant) colorPixels++;
    } else if (channel === 'green') {
      intensity = g;
      isColorDominant = (g > r && g > b && g > 50);
      if (isColorDominant) colorPixels++;
    } else if (channel === 'blue') {
      intensity = b;
      isColorDominant = (b > r && b > g && b > 30) || 
                       (b > 60 && b > r * 1.1 && b > g * 1.1) ||
                       (b > 40 && r < 100 && g < 100);
      if (isColorDominant) {
        colorPixels++;
        intensity = Math.min(255, b * 1.8);
      }
    }
    data[i] = intensity; data[i + 1] = intensity; data[i + 2] = intensity;
  }
  if (channel === 'blue') {
    const colorRatio = colorPixels / totalPixels;
    if (colorRatio > 0.005) {
      console.log(`Blue channel enhanced: ${colorPixels}/${totalPixels} pixels (${(colorRatio*100).toFixed(2)}%)`);
    }
  }
  return new ImageData(data, imageData.width, imageData.height);
}

function enhanceBlueContrast(imageData) {
  const data = new Uint8ClampedArray(imageData.data);
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i], g = data[i + 1], b = data[i + 2];
    let blueIntensity = 0;
    if (b > r && b > g) {
      blueIntensity = Math.min(255, b * 2);
    } else if (b > 60 && (b - r > 10 || b - g > 10)) {
      blueIntensity = Math.min(255, b * 1.5);
    } else if (b > 40 && r < 100 && g < 100) {
      blueIntensity = Math.min(255, b * 1.8);
    } else {
      blueIntensity = Math.max(0, Math.min(r, g, b) * 0.3);
    }
    data[i] = blueIntensity; data[i + 1] = blueIntensity; data[i + 2] = blueIntensity;
  }
  return new ImageData(data, imageData.width, imageData.height);
}

function detectWithOpenCV(imageData, color) {
  if (!cvReady) return null;
  try {
    const src = cv.matFromImageData(imageData);
    let hsv = new cv.Mat();
    cv.cvtColor(src, hsv, cv.COLOR_RGBA2RGB);
    cv.cvtColor(hsv, hsv, cv.COLOR_RGB2HSV);
    let mask = new cv.Mat();
    let low, high;
    if (color === 'red') {
      let mask1 = new cv.Mat(), mask2 = new cv.Mat();
      low = new cv.Scalar(0, 40, 40); high = new cv.Scalar(10, 255, 255); cv.inRange(hsv, low, high, mask1);
      low = new cv.Scalar(170, 40, 40); high = new cv.Scalar(180, 255, 255); cv.inRange(hsv, low, high, mask2);
      cv.add(mask1, mask2, mask); mask1.delete(); mask2.delete();
    } else if (color === 'green') {
      low = new cv.Scalar(35, 30, 30); high = new cv.Scalar(85, 255, 255); cv.inRange(hsv, low, high, mask);
    } else if (color === 'blue') {
      let mask1 = new cv.Mat(), mask2 = new cv.Mat(), mask3 = new cv.Mat();
      low = new cv.Scalar(100, 25, 25); high = new cv.Scalar(130, 255, 255); cv.inRange(hsv, low, high, mask1);
      low = new cv.Scalar(90, 20, 20); high = new cv.Scalar(140, 255, 255); cv.inRange(hsv, low, high, mask2);
      low = new cv.Scalar(105, 15, 30); high = new cv.Scalar(125, 255, 255); cv.inRange(hsv, low, high, mask3);
      cv.add(mask1, mask2, mask); cv.add(mask, mask3, mask); mask1.delete(); mask2.delete(); mask3.delete();
    }
    let kernel3 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3));
    let kernel5 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
    cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel3);
    cv.morphologyEx(mask, mask, cv.MORPH_CLOSE, kernel5);
    cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel3);
    kernel3.delete(); kernel5.delete();
    let rgba = new cv.Mat();
    cv.cvtColor(mask, rgba, cv.COLOR_GRAY2RGBA);
    const result = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
    src.delete(); hsv.delete(); mask.delete(); rgba.delete();
    return result;
  } catch(e) {
    console.error('OpenCV detection error:', e);
    return null;
  }
}

function detect_colored_qr_in_frame_js(imageData, targetColor=null) {
  const COLORS = ['red', 'green', 'blue'];
  for (const color of COLORS) {
    if (targetColor && color !== targetColor) continue;
    try {
      const chImg = extractColorChannel(imageData, color);
      const code = jsQR(chImg.data, chImg.width, chImg.height, { inversionAttempts: 'attemptBoth' });
      if (code && code.data) {
        return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Enhanced-Channel' };
      }
    } catch(e) { console.warn('Enhanced channel decode error', color, e); }
    if (color === 'blue') {
      try {
        const maskImg = createColorMask(imageData, color);
        const code = jsQR(maskImg.data, maskImg.width, maskImg.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Color-Mask' };
        }
      } catch(e) { console.warn('Color mask decode error', color, e); }
    }
    if (cvReady) {
      try {
        const cvProcessed = detectWithOpenCV(imageData, color);
        if (cvProcessed) {
          const code = jsQR(cvProcessed.data, cvProcessed.width, cvProcessed.height, { inversionAttempts: 'attemptBoth' });
          if (code && code.data) {
            return { found: true, decoded: code.data.trim(), colorFound: color, method: 'OpenCV-HSV' };
          }
        }
      } catch(e) { console.warn('OpenCV approach failed for', color, e); }
    }
    if (color === 'blue') {
      try {
        const enhanced = enhanceBlueContrast(imageData);
        const code = jsQR(enhanced.data, enhanced.width, enhanced.height, { inversionAttempts: 'attemptBoth' });
        if (code && code.data) {
          return { found: true, decoded: code.data.trim(), colorFound: color, method: 'Blue-Enhanced' };
        }
      } catch(e) { console.warn('Blue enhancement failed', e); }
    }
  }
  return { found: false };
}

/* ======= Update progress display ======= */
function updateProgressDisplay() {
  const colors = ['red', 'green', 'blue'];
  colors.forEach(color => {
    const element = document.getElementById(`progress${color.charAt(0).toUpperCase() + color.slice(1)}`);
    if (foundResults.has(color)) {
      element.className = 'found-qr';
      element.textContent = `${color === 'red' ? 'ðŸ”´' : color === 'green' ? 'ðŸŸ¢' : 'ðŸ”µ'} ${color.charAt(0).toUpperCase() + color.slice(1)} QR: âœ… ${foundResults.get(color).decoded}`;
    } else {
      element.className = 'pending-qr';
      element.textContent = `${color === 'red' ? 'ðŸ”´' : color === 'green' ? 'ðŸŸ¢' : 'ðŸ”µ'} ${color.charAt(0).toUpperCase() + color.slice(1)} QR: Scanning...`;
    }
  });
}

/* ======= Camera functions ======= */
async function startCamera() {
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: { 
        facingMode: "environment",
        width: { ideal: 1280 },
        height: { ideal: 720 }
      }, 
      audio: false
    });
    video.srcObject = stream;
    await video.play();
    canvasDisp.width = video.videoWidth; 
    canvasDisp.height = video.videoHeight;
    preview.width = Math.min(820, video.videoWidth); 
    preview.height = Math.min(360, video.videoHeight);
    scanBox.x = Math.floor((canvasDisp.width - SCAN_SIZE)/2);
    scanBox.y = Math.floor((canvasDisp.height - SCAN_SIZE)/2);
    scanStartTime = Date.now();
    foundResults.clear();
    actionsTriggered = false;
    scannerRunning = true;
    log("Camera started: " + video.videoWidth + "x" + video.videoHeight);
    overlayText.textContent = "Scanning for 3 color QR codes...";
    updateProgressDisplay();
    processFrame();
    return true;
  } catch(e) {
    overlayText.textContent = "Camera access denied or unavailable.";
    log("Camera start error: " + e);
    return false;
  }
}

function stopCamera() {
  if (stream) stream.getTracks().forEach(t=>t.stop());
  if (animationFrameId) { cancelAnimationFrame(animationFrameId); animationFrameId = null; }
  scannerRunning = false;
  overlayText.textContent = "Scanner stopped.";
  log("Camera stopped.");
}

/* ======= COCO model loader ======= */
async function loadCocoModel() {
  try {
    overlayText.textContent = "Loading object detection model...";
    log("Loading COCO-SSD model (this may take a moment)...");
    cocoModel = await cocoSsd.load();
    cocoReady = true;
    overlayText.textContent = "Object detection model ready.";
    log("âœ… coco-ssd loaded.");
  } catch (e) {
    cocoReady = false;
    log("Failed to load coco-ssd:", e);
    overlayText.textContent = "Object detection model failed to load.";
  }
}
// Kick off model load
loadCocoModel();

/* ======= Main processing loop ======= */
let qrDecoderBusy = false;
let frameSkipCounter = 0;
let latestDetections = []; // from coco
function processFrame() {
  if (!scannerRunning) return;
  animationFrameId = requestAnimationFrame(processFrame);
  if (!video || video.readyState < 2) return;
  
  // Skip frames for better performance (process every 3rd frame)
  frameSkipCounter++;
  if (frameSkipCounter % 3 !== 0 && foundResults.size < 3) return;
  
  ctxDisp.drawImage(video, 0, 0, canvasDisp.width, canvasDisp.height);
  
  // Update preview less frequently and draw boxes if detections exist
  if (frameSkipCounter % 5 === 0) {
    try {
      const tmp = document.createElement('canvas');
      tmp.width = canvasDisp.width; tmp.height = canvasDisp.height;
      const tmpCtx = tmp.getContext('2d');
      tmpCtx.drawImage(canvasDisp, 0, 0);
      // Draw scan box on preview
      tmpCtx.strokeStyle = '#00ff00';
      tmpCtx.lineWidth = 2;
      tmpCtx.strokeRect(scanBox.x, scanBox.y, scanBox.size, scanBox.size);
      // Draw latest detections (if any)
      if (latestDetections && latestDetections.length > 0 && enableDetectCheckbox.checked) {
        tmpCtx.lineWidth = 2;
        tmpCtx.font = '18px Arial';
        for (const d of latestDetections) {
          tmpCtx.strokeStyle = 'rgba(255,0,0,0.9)';
          tmpCtx.fillStyle = 'rgba(255,0,0,0.7)';
          const [x,y,w,h] = d.bbox;
          tmpCtx.strokeRect(x, y, w, h);
          tmpCtx.fillRect(x, y-22, tmpCtx.measureText(d.class + ' ' + (d.score*100).toFixed(0) + '%').width + 8, 22);
          tmpCtx.fillStyle = '#fff';
          tmpCtx.fillText(d.class + ' ' + (d.score*100).toFixed(0) + '%', x+4, y-6);
        }
      }
      preview.src = tmp.toDataURL('image/png');
    } catch(e) {}
  }
  
  if (qrDecoderBusy) return;
  qrDecoderBusy = true;
  
  setTimeout(async () => {
    try {
      const imageData = ctxDisp.getImageData(scanBox.x, scanBox.y, scanBox.size, scanBox.size);
      const targetFilter = (colorFilterEl.value === "Any") ? null : colorFilterEl.value.toLowerCase();
      const colorOrder = targetFilter ? [targetFilter] : ['blue', 'red', 'green'];
      for (const color of colorOrder) {
        if (foundResults.has(color)) continue;
        const detection = detect_colored_qr_in_frame_js(imageData, color);
        if (detection.found && detection.decoded) {
          const decodedClean = detection.decoded.trim();
          foundResults.set(color, { decoded: decodedClean, method: detection.method || 'unknown' });
          log(`âœ… Decoded ${color.toUpperCase()}: ${decodedClean} (${detection.method})`);
          TTS.speak(`${color} QR found`);
          updateProgressDisplay();
          break;
        }
      }
      
      const allColors = ['red', 'green', 'blue'];
      const foundColors = Array.from(foundResults.keys());
      if (!actionsTriggered && allColors.every(c => foundColors.includes(c))) {
        triggerAllActionsOnce();
      }
      const scanTime = (Date.now() - scanStartTime) / 1000;
      if (foundColors.length === 0) {
        overlayText.textContent = `Scanning for QR codes... (${scanTime.toFixed(1)}s)`;
      } else if (foundColors.length < 3) {
        overlayText.textContent = `Found ${foundColors.length}/3 QR codes - keep scanning...`;
      } else {
        overlayText.textContent = `All 3 QR codes found! Processing...`;
      }
      
      // PERIODIC object detection using coco model (full frame detection)
      const now = performance.now();
      if (enableDetectCheckbox.checked && cocoReady && (now - lastDetectTime > DETECTION_INTERVAL_MS)) {
        lastDetectTime = now;
        try {
          // Use a smaller offscreen canvas for speed
          const off = document.createElement('canvas');
          const D_W = 480; // scale to this width for detection
          const scale = D_W / canvasDisp.width;
          off.width = D_W;
          off.height = Math.floor(canvasDisp.height * scale);
          const offCtx = off.getContext('2d');
          offCtx.drawImage(canvasDisp, 0, 0, off.width, off.height);
          // run detection (async)
          const predictions = await cocoModel.detect(off);
          // filter predictions by score
          const preds = predictions.filter(p => p.score >= SCORE_THRESHOLD);
          // map bbox back to original canvas coordinates
          latestDetections = preds.map(p => {
            const [x,y,w,h] = p.bbox;
            const scaleBack = canvasDisp.width / off.width;
            return { class: p.class, score: p.score, bbox: [x*scaleBack, y*scaleBack, w*scaleBack, h*scaleBack] };
          });
          // ALERT logic: choose the "most ahead" object (largest bbox height and near center)
          let candidate = null;
          const fh = canvasDisp.height;
          const fw = canvasDisp.width;
          for (const det of latestDetections) {
            const [x,y,w,h] = det.bbox;
            const cx = x + w/2;
            const centerDelta = Math.abs(cx - fw/2) / fw; // 0..0.5
            // prefer objects that are near center and large
            const score = (h / fh) * (1.0 - Math.min(centerDelta / 0.5, 1.0));
            if (!candidate || score > candidate.score) candidate = {det, score};
          }
          if (candidate) {
            const det = candidate.det;
            const [x,y,w,h] = det.bbox;
            const cx = x + w/2;
            const centerDelta = Math.abs(cx - fw/2) / fw;
            // consider "ahead" if within CENTER_TOLERANCE and reasonably large
            const isAhead = (centerDelta <= CENTER_TOLERANCE) && (h / fh >= 0.10);
            if (isAhead) {
              const cls = det.class;
              const nowTs = Date.now();
              if (!lastAlertAt[cls] || (nowTs - lastAlertAt[cls] > alertCooldown)) {
                // estimate distance heuristically
                const ratio = (h / fh);
                let distMeters = (DISTANCE_ESTIMATE_SCALE / Math.max(ratio, 0.02)); // simple heuristic
                distMeters = Math.min(Math.max(distMeters, 0.2), 20.0);
                const spoken = `Object ahead: ${cls}, approximately ${distMeters.toFixed(1)} meters.`;
                TTS.speak(spoken, true);
                overlayText.textContent = `âš ï¸ Obstacle ahead: ${cls} ~${distMeters.toFixed(1)}m`;
                log(`[OBSTACLE] ${cls} @ approx ${distMeters.toFixed(1)}m`);
                lastAlertAt[cls] = nowTs;
              }
            }
          }
        } catch (e) {
          console.warn("Object detection error:", e);
        }
      }
      
    } catch(e) { console.error("Frame processing error:", e); }
    finally { qrDecoderBusy = false; }
  }, 40);
}

/* ======= Trigger all actions after 3 QRs found (keeps your original flow) ======= */
function triggerAllActionsOnce() {
  if (actionsTriggered) return;
  actionsTriggered = true;
  log("ðŸŽ‰ All three color QR codes detected!");
  TTS.speak("All QR codes detected. Processing information.", true);
  const greenQR = foundResults.get('green')?.decoded || '';
  const blueQR = foundResults.get('blue')?.decoded || '';  
  const redQR = foundResults.get('red')?.decoded || '';
  stopCamera();
  setTimeout(() => { log("ðŸ“ Map information: " + greenQR); TTS.speak("Map displayed. " + greenQR); drawMap(); mapModal.style.display = 'flex'; }, 500);
  setTimeout(() => { log("â™¿ Accessibility info: " + blueQR); TTS.speak("Accessibility information: " + blueQR); overlayText.textContent = `Accessibility: ${blueQR}`; }, 2000);
  setTimeout(() => { currentLocation = redQR; log("ðŸ“ Current location: " + redQR); TTS.speak("Your current location is: " + redQR); overlayText.textContent = `Current location: ${redQR}`; }, 4000);
  setTimeout(() => { if (SR_AVAILABLE) ask_destination_via_voice(); else show_destination_modal(); }, 6000);
}

/* ======= Destination selection & navigation (kept same as your original functions) ======= */
/* show_destination_modal, findBestLocationMatch, ask_destination_via_voice, start_navigation, navigationDialog, handleDecoded, drawMap etc. */
/* For brevity, I will reuse the implementations you had; they are unchanged from your original file. */

function show_destination_modal() {
  if (!currentLocation) { alert("No current location detected. Please scan QR codes first."); return; }
  TTS.speak("Using text input for destination selection. A dialog box will appear with numbered options.");
  const candidates = Object.keys(node_coords).filter(n => n !== currentLocation);
  const candidateList = candidates.map((place, index) => `${index + 1}. ${place}`).join('\n');
  const message = `NAVIGATION DESTINATION SELECTION\n\nCurrent location: ${currentLocation}\n\nWhere would you like to go?\n\nAvailable destinations:\n${candidateList}\n\nPlease type the destination name or number:`;
  const firstFiveOptions = candidates.slice(0, 5).join(', ');
  TTS.speak(`First few destinations available: ${firstFiveOptions}. Type the name or number in the dialog box.`);
  const dest = prompt(message);
  if (dest) {
    let destination = dest.trim();
    const destNumber = parseInt(destination);
    if (!isNaN(destNumber) && destNumber >= 1 && destNumber <= candidates.length) {
      destination = candidates[destNumber - 1];
      log(`Selected by number: ${destNumber} -> ${destination}`);
    } else {
      const bestMatch = findBestLocationMatch(destination, candidates);
      if (bestMatch) {
        destination = bestMatch;
        log(`Text match found: ${dest} -> ${destination}`);
      } else {
        TTS.speak("Destination not found. Please try again.");
        alert("Destination not found. Please try again with exact location name or number.");
        setTimeout(() => show_destination_modal(), 500);
        return;
      }
    }
    TTS.speak(`You selected ${destination}. Confirming navigation start.`);
    const confirmMessage = `Navigate to: ${destination}?\n\nPress OK to start navigation, Cancel to choose again.`;
    if (confirm(confirmMessage)) {
      start_navigation(destination);
    } else {
      TTS.speak("Selection cancelled. Let me ask again.");
      setTimeout(() => show_destination_modal(), 500);
    }
  } else {
    TTS.speak("No destination selected.");
    const retry = confirm("No destination selected. Would you like to try voice input instead?");
    if (retry && SR_AVAILABLE) { setTimeout(() => ask_destination_via_voice(), 500); }
    else if (retry) { setTimeout(() => show_destination_modal(), 500); }
    else { TTS.speak("Navigation cancelled."); overlayText.textContent = "Navigation cancelled"; }
  }
}

function findBestLocationMatch(input, candidates) {
  const inputLower = input.toLowerCase().trim();
  let match = candidates.find(c => c.toLowerCase() === inputLower);
  if (match) return match;
  match = candidates.find(c => c.toLowerCase().includes(inputLower));
  if (match) return match;
  match = candidates.find(c => c.toLowerCase().split(' ').some(word => inputLower.includes(word) || word.includes(inputLower)));
  if (match) return match;
  return null;
}

function ask_destination_via_voice() {
  if (!currentLocation) { alert("Please scan your current location first."); return; }
  if (!SR_AVAILABLE) { log("Speech recognition not available in this browser."); show_destination_modal(); return; }
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) { log("No SpeechRecognition implementation."); show_destination_modal(); return; }
  const r = new SpeechRecognition();
  r.lang = 'en-US';
  r.interimResults = false;
  r.maxAlternatives = 3;
  r.onstart = () => { log("ðŸŽ¤ Listening for destination..."); TTS.speak("Where would you like to go? Please say your destination now."); overlayText.textContent = "ðŸŽ¤ Listening... Please say your destination"; };
  r.onresult = (evt) => {
    const text = evt.results[0][0].transcript;
    log("ðŸŽ¤ Recognized speech: " + text);
    const candidates = Object.keys(node_coords).filter(n => n !== currentLocation);
    const bestMatch = findBestLocationMatch(text, candidates);
    if (bestMatch) {
      TTS.speak(`Did you mean ${bestMatch}? Please say yes or no.`);
      overlayText.textContent = `Confirm destination: ${bestMatch}`;
      const r2 = new SpeechRecognition();
      r2.lang = 'en-US';
      r2.onresult = (e2) => {
        const confirm = e2.results[0][0].transcript.toLowerCase();
        log("ðŸŽ¤ Confirmation: " + confirm);
        if (confirm.includes('yes') || confirm.includes('yeah') || confirm.includes('yup') || confirm.includes('correct')) {
          start_navigation(bestMatch);
        } else {
          TTS.speak("Okay, let me try again.");
          setTimeout(() => ask_destination_via_voice(), 1000);
        }
      };
      r2.onerror = () => { log("Confirmation error, switching to manual input."); show_destination_modal(); };
      r2.start();
    } else {
      TTS.speak("I couldn't find that destination. Let me try again.");
      setTimeout(() => ask_destination_via_voice(), 1000);
    }
  };
  r.onerror = (e) => { log("Speech recognition error: " + e.error); show_destination_modal(); };
  r.start();
}

function start_navigation(destination) {
  if (!currentLocation) { alert("No current location. Please scan QR codes first."); return; }
  if (!destination) { alert("No destination selected."); return; }
  const res = dijkstra(graph, currentLocation, destination);
  if (!res.path.length || res.cost === Infinity) {
    log("âŒ No path found to destination.");
    TTS.speak("Sorry, no path found to that destination.");
    alert("Routing error: no path found.");
    return;
  }
  log(`ðŸ—ºï¸ Route: ${res.path.join(' â†’ ')} | distance ${res.cost.toFixed(2)}m`);
  TTS.speak(`Navigation started to ${destination}. Total distance ${res.cost.toFixed(0)} meters.`);
  overlayText.textContent = `Navigating to: ${destination} (${res.cost.toFixed(0)}m)`;
  navigationDialog(res.path, res.cost);
}

function navigationDialog(path, total_cost) {
  let idx = 0;
  currentNavigationTarget = path[path.length - 1];
  function showStep() {
    if (idx >= path.length - 1) {
      const finalText = `You are approaching your destination: ${path[path.length - 1]}. Look for the QR code to confirm your arrival.`;
      TTS.speak(finalText);
      overlayText.textContent = `Final step: Look for ${path[path.length - 1]} QR code`;
      setTimeout(() => {
        if (!scannerRunning) { log("ðŸ”„ Restarting camera for arrival confirmation..."); startBtn.click(); }
      }, 2000);
      return;
    }
    const current = path[idx];
    const next = path[idx + 1];
    let instruction;
    if (idx === 0) {
      instruction = `${get_initial_direction_simple(node_coords[current], node_coords[next])} towards ${next}.`;
    } else {
      const prev = path[idx - 1];
      instruction = `At ${current}: ${get_turn_direction(node_coords[prev], node_coords[current], node_coords[next])} towards ${next}.`;
    }
    const distance = (graph[current] && graph[current][next]) ? graph[current][next] : 0;
    const spoken = `${instruction} Distance ${distance.toFixed(0)} meters.`;
    TTS.speak(spoken);
    log(`ðŸ“ Step ${idx + 1}: ${spoken}`);
    overlayText.textContent = `Step ${idx + 1}: ${instruction}`;
    if (confirm(spoken + "\n\nPress OK for next step, Cancel to stop navigation.")) {
      idx++;
      setTimeout(showStep, 500);
    } else {
      TTS.speak("Navigation cancelled.", true);
      currentNavigationTarget = null;
      overlayText.textContent = "Navigation cancelled";
    }
  }
  showStep();
}

/* ======= Arrival handling (keeps original behavior) ======= */
function handleDecoded(decoded, color) {
  const decodedClean = decoded.trim();
  if (currentNavigationTarget) {
    const target = (currentNavigationTarget || "").toLowerCase();
    const detected = decodedClean.toLowerCase();
    if (detected === target || detected.includes(target) || target.includes(detected)) {
      log(`ðŸŽ‰ Arrival confirmed: ${decodedClean}`);
      TTS.speak(`You have successfully arrived at ${decodedClean}`, true);
      currentLocation = decodedClean; currentNavigationTarget = null;
      stopCamera(); overlayText.textContent = `âœ… Arrived: ${decodedClean}`;
      setTimeout(() => { alert(`ðŸŽ‰ Arrival Confirmed!\n\nYou have reached: ${decodedClean}`); }, 1000);
      return;
    } else {
      if (decodedClean !== currentLocation) {
        currentLocation = decodedClean;
        log(`ðŸ“ Passed checkpoint: ${decodedClean} [${color}]`);
        TTS.speak(`Passed ${decodedClean}`);
        overlayText.textContent = `Checkpoint: ${decodedClean}`;
      }
      return;
    }
  }
  if (decodedClean !== currentLocation) {
    currentLocation = decodedClean;
    log(`ðŸ“ Current location updated: ${decodedClean} [${color}]`);
    TTS.speak(`Current location: ${decodedClean}`);
    overlayText.textContent = `Location: ${decodedClean}`;
    setTimeout(() => {
      if (SR_AVAILABLE) { ask_destination_via_voice(); } else { show_destination_modal(); }
    }, 1000);
  }
}

/* ======= Map drawing ======= (unchanged) */
function drawMap() {
  const ctx = mapCanvas.getContext('2d');
  ctx.clearRect(0, 0, mapCanvas.width, mapCanvas.height);
  const cw = mapCanvas.width, ch = mapCanvas.height, margin = 40;
  const xs = Object.values(node_coords).map(p => p[0]);
  const ys = Object.values(node_coords).map(p => p[1]);
  const minx = Math.min(...xs), maxx = Math.max(...xs);
  const miny = Math.min(...ys), maxy = Math.max(...ys);
  const project = (p) => {
    const sx = (p[0] - minx) / (maxx - minx || 1);
    const sy = (p[1] - miny) / (maxy - miny || 1);
    return [
      margin + Math.floor(sx * (cw - margin * 2)),
      margin + Math.floor(sy * (ch - margin * 2))
    ];
  };
  ctx.strokeStyle = "#ddd"; ctx.lineWidth = 1;
  for (const a in graph) {
    for (const b in graph[a]) {
      if (node_coords[a] && node_coords[b]) {
        const pa = project(node_coords[a]); const pb = project(node_coords[b]);
        ctx.beginPath(); ctx.moveTo(pa[0], pa[1]); ctx.lineTo(pb[0], pb[1]); ctx.stroke();
      }
    }
  }
  ctx.fillStyle = "#333"; ctx.font = "12px Arial";
  for (const name in node_coords) {
    const p = project(node_coords[name]);
    if (name === currentLocation) {
      ctx.fillStyle = "#ff4444"; ctx.beginPath(); ctx.arc(p[0], p[1], 8, 0, Math.PI * 2); ctx.fill(); ctx.fillStyle = "#fff";
    } else {
      ctx.fillStyle = "#666"; ctx.beginPath(); ctx.arc(p[0], p[1], 4, 0, Math.PI * 2); ctx.fill(); ctx.fillStyle = "#333";
    }
    const metrics = ctx.measureText(name); const textX = p[0] + 10; const textY = p[1] + 4;
    ctx.fillStyle = "rgba(255,255,255,0.8)"; ctx.fillRect(textX - 2, textY - 10, metrics.width + 4, 14);
    ctx.fillStyle = "#333"; ctx.fillText(name, textX, textY);
  }
}

/* ======= UI Event Handlers ======= */
startBtn.onclick = async () => { if (scannerRunning) { log("Scanner already running."); return; } const ok = await startCamera(); if (!ok) return; };
stopBtn.onclick = () => { stopCamera(); };
restartBtn.onclick = () => { stopCamera(); foundResults.clear(); actionsTriggered = false; scanStartTime = Date.now(); setTimeout(() => { startBtn.click(); }, 300); };
voiceDestBtn.onclick = () => { ask_destination_via_voice(); };
mapBtn.onclick = () => { drawMap(); mapModal.style.display = 'flex'; };
closeMap.onclick = () => { mapModal.style.display = 'none'; };

/* ======= OpenCV init (unchanged) ======= */
function onOpenCvReady() { cvReady = true; log("âœ… OpenCV.js loaded and ready."); overlayText.textContent = "OpenCV loaded - Enhanced color detection enabled"; }
if (typeof cv !== 'undefined') {
  if (cv && cv.Mat) { onOpenCvReady(); } else { cv['onRuntimeInitialized'] = () => { onOpenCvReady(); }; }
} else {
  setTimeout(() => { if (!cvReady) { log("âš ï¸ OpenCV timeout - using fallback color detection."); overlayText.textContent = "Using basic color detection (OpenCV not loaded)"; } }, 8000);
}

/* ======= Cleanup ======= */
window.addEventListener('beforeunload', () => { if (stream) stream.getTracks().forEach(t => t.stop()); speechSynthesis.cancel(); });

/* ======= Initialization ======= */
overlayText.textContent = "Ready. Click 'Start Scan' to begin scanning for 3 color QR codes.";
log("ðŸš€ Indoor Navigation App initialized.");
log(`ðŸ“± Speech Recognition available: ${SR_AVAILABLE}`);
log("ðŸ“‹ Scan sequence: Red (location) + Green (map) + Blue (accessibility) = Navigation ready");

</script>
</body>
</html>
